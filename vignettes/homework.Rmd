---
title: "All Homework"
author: '19037'
date: "2020/01/03"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{All Homework}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Overview
This rmarkdown is a summary of homework.



# 1
## Question
  The allbacks data frame gives measurements on the volume and weight of 15 books, some of which are softback (pb) and some of which are hardback (hb).
  Use knitr to produce at least 3 examples(xtables,figures,texts).
  
### answer
  First,as following,the allbacks data will be represented in the table directly.
```{r, results = 'asis'}
library(DAAG)
library(xtable)
data(allbacks)
print(xtable(allbacks[1:15, ]),type='html')
```

  Table which is presented above gives measurements on the volume and weight of 15 books, some of which are softback (pb) and some of which are hardback (hb).We can enter these columns of data,then plot volume against weight to give Figure,thus:
```{r}
attach(allbacks)
plot(volume,weight)
detach(allbacks)
```


# 2

## Exercise 3.4
  The Rayleigh density [156, Ch. 18] is 
  $f(x)=x/(\sigma^2)*exp(-x^2/(2*\sigma^2)),x\geq 0,\sigma> 0$ 
  Develop an algorithm to generate random samples from a Rayleigh($\sigma$) distribution. Generate Rayleigh($\sigma$) samples for several choices of $\sigma>0$ and check that the mode of the generated samples is close to the theoretical mode $\sigma$ (check the histogram). 

### answer 
  Here $F_{X}(x)=1-exp(-x^2/(2*\sigma^2))$ for 0 $x>0$, and $F_{X}(u)=sqrt(-2*(sigma^2)*log(1-u))$. Generate all n required random uniform numbers as vector u. Then $u^(1/3)$ is a vector of length n containing the sample $x1,...,xn$.
  In this exercise, I choose $\sigma$ as 2,4,6,8.

```{r}
n <- 100000
u <- runif(n)
m <- c(2,4,6,8)
#par(mfrow=c(2,2))
for(sigma in m){
x <- sqrt(-2*(sigma^2)*log(1-u))
#density histogram of sample
hist(x, prob = TRUE, main = paste("sigma = ",sigma))
y <- seq(0, 60, .001)
#density curve f(x)
lines(y, y/(sigma^2)*exp(-(y^2)/(2*sigma^2))) 
}
```
  
  The histogram and density plot in figure that we polted suggests that the empirical and theoretical distributions approximately agree. 
  

##  Exercise 3.11
  Generate a random sample of size 1000 from a normal location mixture. The components of the mixture have $N(0,1)$ and $N(3,1)$ distributions with mixing probabilities $p_{1}$ and $p_{2}=1-p_{1}$. Graph the histogram of the sample with density superimposed, for $p_{1}=0.75$. Repeat with different values for $p_{1}$ and observe whether the empirical distribution of the mixture appears to be bimodal. Make a conjecture about the values of $p_{1}$ that produce bimodal mixtures.

### answer
  Generate a random sample of size 1000 from a normal location mixture. The components of the mixture have $N(0,1)$ and $N(3,1)$ distributions with mixing probabilities $p_{1}$ and $p_{2}=1-p_{1}$.
  In this exercise, except for p=0.75 as required, I choose p=0.1, 0.3, 0.5, 0.6, 0.9.
```{r}
n <- 1e6
l <- c(0.1,0.3,0.5,0.6,0.75,0.9)
#par(mfrow=c(2,3))
 for(p in l){
  x <- sample(c(0,1), size = n, replace = TRUE, prob = c(p, 1-p))
  y <- vector(length=n)
  for(i in 1:n){
    if(x[i] == 0) 
    y[i] <- rnorm(1, mean = 0, sd = 1)
    else y[i] <- rnorm(1, mean = 3, sd = 1)
  }
 hist(y, prob = TRUE, main = paste("p = ", p))
}
```
  
  Graphing the histogram of the sample with density superimposed, which used different values of $p_{1}$. Make a conjecture about the values of $p_{1}$, then we can produce bimodal mixtures. 
  And after observing, we can find that the empirical distribution of the mixture appears to be bimodal. 
  

## Exercise 3.18
  Write a function to generate a random sample from a $wd(\sum ,n)$ (Wishart) distribution for $n>d+1\geq1$, based on Bartlett’s decomposition. 

### answer
  Choosing a matrix X based on Bartlett’s decomposition,. $X^{T}*X$ is a $wd(\sum ,n)$ (Wishart) distribution.  
```{r}
library(MASS)
n <- 10
d <-5
m <- matrix(1:d^2, d, d)
sigma <- cov(m)
X <- mvrnorm(d, mu=1:d, sigma)
Y <- t(X)
Z <- Y%*%X
Z
```
  
  The matrix Z (produced by matrix X and Y) is the matrix which is required.



# 3

## Exercise 5.1
  Compute a Monte Carlo estimate of $\int_{0}^{\pi /3}sintdt$ and compare your estimate with the exact value of the integral. 

### answer
```{r}
library(scales)
m <- 10000
x <- runif(m, min = 0, max = pi/3)
theta.hat <- mean(sin(x))*(pi/3)
print(theta.hat)
print(-cos(pi/3)+1)
```
 
  a Monte Carlo estimate of $\int_{0}^{\pi /3}sintdt$ is `r theta.hat` and the estimate of the exact value of the integral is `r -cos(pi/3)+1`. Obviously, the Monte Carlo estimate value is approximate to the exact value.
  
  
## Exercise 5.10
  Use Monte Carlo integration with antithetic variables to estimate $\int_{0}^{1}\frac{e^{-x}}{1+x^2}dx$, and find the approximate reduction in variance as a percentage of the variance without variance reduction.

### answer
```{r}
library(scales)
m <- 10000
U <- runif(m)
#simple MC
T1 <- exp(-U)/(1+U^2)
#MC with antithetic variables
U1 <- runif(m/2)
U2 <- 1-U1
T2 <- (exp(-U1)/(1+U1^2)+exp(-U2)/(1+U2^2))/2
#print the variance of T1 and T2
mean(T1)
mean(T2)
var(T1)
var(T2)
(var(T1)-var(T2))/var(T1)
```
 
  The approximate reduction in variance as a percentage `r percent((var(T1)-var(T2))/var(T1))`of the variance without variance reduction.
  

## Exercise 5.15
  Obtain the stratified importance sampling estimate in Example 5.13 and compare it with the result of Example 5.10.

### answer
  In Example5.10, our best result was obtained with importance function $f_3(x)=\frac{e^{-x}}{1-e^{-1}}, 0<x<1$. From 10000 replicates we obtained the estimate $\tilde{\theta }=0.5257801$ and an estimated standard error 0.0970314. Now divide the interval (0,1) into five subintervals, $(\frac{j}{5},\frac{j+1}{5}), j=0,1,\cdots ,4$. Then on the $j^{th}$ subinterval variables are generated from the density $\frac{5*e^{-x}}{1-e^{-1}}, \frac{j-1}{5}<x<\frac{j}{5}$

```{r}
M <- 1e5 
k <- 5 
N <- 50
T2 <- numeric(k)
est <- matrix(0, N, 2)
g <- function(x){
  (1-exp(-1))/(1+x^2)
}
for (i in 1:N) {
#importance sampling estimate  
  u<-runif(M)
  x<--log(1-(1-exp(-1))*u)
  est[i, 1] <- mean(g(x))
  for(j in 1:k){
#stratified importance sampling estimate    
    F1<-(1-exp((1-j)/5))/(1-exp(-1))
    F2<-(1-exp(-j/5))/(1-exp(-1))
    u<- runif((F2-F1)*M)
    x<- -log(1-(1-exp(-1))*((F2-F1)*u+F1))
    T2[j]<-mean((F2-F1)*g(x))
  }
  est[i, 2] <- sum(T2)
}
#print the outcoming
apply(est,2,mean)
apply(est,2,var)
apply(est,2,sd)
```
  
conclusion:        
1. The mean of importance sampling estimate and stratified importance sampling estimate is `r apply(est,2,mean)`.             
2. The variance of importance sampling estimate and stratified importance sampling estimate is `r apply(est,2,var)   `.              
3. The standard error of importance sampling estimate and stratified importance sampling estimate is `r apply(est,2,sd)`.              
4. It is easy to find that the variance of importance sampling estimate is bigger than  stratified importance sampling estimate's. Obviously, the stratified importance sampling estimate's variance is reduced more, this method is a better choice.     


# 4
## Exercise 6.5
  Suppose a 95% symmetric t-interval is applied to estimate a mean, but the sample data are non-normal. Then the probability that the confidence interval covers the mean is not necessarily equal to 0.95. Use a Monte Carlo experiment to estimate the coverage probability of the t-interval for random samples of $\chi^{2}(2)$ data with sample size n = 20. Compare your t-interval results with the simulation results in Example 6.4. (The t-interval should be more robust to departures from normality than the interval for variance.) 

### answer
Example 6.4   
If $X_1,\cdots, X_n$ is a random sample from a Normal $(u,\sigma^2)$ distribution, $n\geqslant 2$, and $S^2$ is the sample variance, then $V = \frac{(n-1)S^2}{\sigma^2}\sim \chi^2(n-1)$    
A one side $100(1-\alpha)%$ confidence interval is given by $(0,\frac{(n-1)S^2}{\chi^2_\alpha})$, where $\chi^2_\alpha$ is the $\alpha$-quantile of the $\chi^2(n-1)$ distribution. If the sampled population is normal with variance $\sigma^2$, then the probability that the confidence interval contains $\sigma^2$ is $1-\alpha$.     
   
```{r}
#x is from a normal distribution 
library(scales)
n <- 20
alpha <- 0.05
UCL1 <- replicate(1000, expr={
  x <- rnorm(n, mean=0, sd=2)
  (n-1)*var(x) / qchisq(alpha, df=n-1)
})
sum(UCL1 > 4)
mean(UCL1 > 4)
```
The result is that `r sum(UCL1 > 4)` intervals satisfied (UCL1 > 4), so the empirical confidence level is `r percent(sum(UCL1 > 4)/1000)` in this experiment. The result will vary but should be close to the theoretical value, `r percent(mean(UCL1 > 4))`.      
    
  
```{r}
#x is from a chi-square data.
n <- 20 
alpha <- 0.05 
UCL2 <- replicate(1000, expr = { 
  x <- rchisq(n, df = 2) 
  (n-1) * var(x) / qchisq(alpha, df = n-1) 
})
sum(UCL2 > 4)
mean(UCL2 > 4) 
```
The result is that `r sum(UCL2 > 4)` intervals satisfied (UCL2 > 4), so the empirical confidence level is `r percent(sum(UCL2 > 4)/1000)` in this experiment. The result will vary but should be close to the theoretical value, `r percent(mean(UCL2 > 4))`. 


In exercise 6.5
```{r}
n <- 20
alpha <- 0.05
U1 <- replicate(1000, expr={
  x <- rchisq(n, df = 2)
  mean(x) - sqrt(var(x)/n)* qt(alpha/2, df = n-1)
})
U2 <- replicate(1000, expr={
  x <- rchisq(n, df = 2)
  mean(x) + sqrt(var(x)/n)* qt(alpha/2, df = n-1)
})
mean(U1 > 2 & U2 < 2)
```
  The coverage probability of the t-interval for random samples of $\chi^{2}(2)$ data with sample size n = 20 is `r percent(mean(U1 > 2 & U2 < 2))`, it is very approximate to 95%.


discuss: 
if x is from normal distribution, how about the coverage probablity?
```{r}
n <- 20
alpha <- 0.05
U3 <- replicate(1000, expr={
  x <- rnorm(n, mean = 0, sd = 2 )
  mean(x) - sqrt(var(x)/n)* qt(alpha/2, df = n-1)
})
U4 <- replicate(1000, expr={
  x <- rnorm(n, mean = 0, sd = 2 )
  mean(x) + sqrt(var(x)/n)* qt(alpha/2, df = n-1)
})
mean(U3 > 0 & U4 < 0)
```
The coverage probability is `r percent(mean(U3 > 0 & U4 < 0))`, the result is very well.


## Exercise 6.6
  Estimate the 0.025, 0.05, 0.95, and 0.975 quantiles of the skewness $\sqrt{b_1}$ under normality by a Monte Carlo experiment. Compute the standard error of the estimates from (2.14) using the normal approximation for the density (with exact variance formula). Compare the estimated quantiles with the quantiles of the large sample approximation $\sqrt{b_1}\approx N(0,6/n)$

### answer  
2.14 $Var(\hat{x_q})=\frac{q(1-q)}{nf(x_q)^2}$
```{r}
#Estimate the quantiles of the skewness under normality by a Monte Carlo experiment
n <- 1000
m <- 10000
sk <- numeric(n)
for (i in 1:m){
  x <- rnorm(n)
  xbar <- mean(x) 
  m3 <- mean((x - xbar)^3) 
  m2 <- mean((x - xbar)^2)
  sk[i] <- m3 / m2^1.5  
}
y1 <- unname(quantile(sk,c(0.025, 0.05, 0.95, 0.975)))
y1
```
The quantiles of the skewness under normality by a Monte Carlo experiment is `r y1`


```{r}
#Compute the standard error of the estimates from (2.14) using the normal approximation for the density (with exact variance formula)
n <- 1000
q <- c(0.025, 0.05, 0.95, 0.975)
f <- qnorm(q, mean = 0, sd = sqrt(6*(n-2)/((n+1)*(n+3))))
sd <- sqrt(q*(1-q)/(n*f^2))
sd
```
The standard error of the estimates from (2.14) using the normal approximation for the density (with exact variance formula) is `r sd`  


```{r}
#estimated quantiles with the quantiles of the large sample approximation N(0,6/n)
n <- 1000
y2 <- qnorm(c(0.025, 0.05, 0.95, 0.975), mean = 0, sd = sqrt(6/n))
y2
```
The quantiles with the quantiles of the large sample approximation N(0,6/n) is `r y2`


```{r}
#compare the quantiles
data.frame(quantiles = c(0.025, 0.05, 0.95, 0.975), q_MC_est = y1, q_sample_approximation = y2, sd)
```
From the table, we can find the estimated quantiles with the quantiles of the large sample approximation $\sqrt{b_1}\approx N(0,6/n)$ are almost same.


# 5
## Exercise 6.7
  Estimate the power of the skewness test of normality against symmetric $Beta(\alpha,\alpha)$ distributions and comment on the results. Are the results different for heavy-tailed symmetric alternatives such as $t(v)$?  
  
### answer
symmetric Beta distribution
```{r}
alpha <- 1
n <- 100 
m <- 2500 
epsilon <-seq(0, 1, length.out = 30) 
N <- length(epsilon) 
power <- numeric(N) 

#computes the sample skewness coeff. 
sk <- function(x) { 
  xbar <- mean(x) 
  m3 <- mean((x - xbar)^3) 
  m2 <- mean((x - xbar)^2) 
  return( m3 / m2^1.5 ) 
  }

#critical value for the skewness test 
cv <- qnorm(0.975, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))

for (j in 1:N) { 
  #for each epsilon 
  e <- epsilon[j] 
  sktests <- numeric(m)
  for (i in 1:m) {
    #for each replicate   
    Y <- sample(0:1, size = n, replace = TRUE,prob = c(1-e, e)) 
    x <- rbeta(n, alpha, alpha) * (Y == 0) + rbeta(n, alpha, 100*alpha) * (Y == 1)
    sktests[i] <- (abs(sk(x)) >= cv)
  }
  power[j] <- mean(sktests) 
} 

#plot power vs epsilon
plot(epsilon, power, type = "b", xlab = bquote(epsilon), ylim = c(0,1)) 
#abline(h = .1, lty = 3)
se <- sqrt(power * (1-power) / m)
#add standard errors
lines(epsilon, power+se, lty = 3)
lines(epsilon, power-se, lty = 3)
```
  
  By considering the figure, the power is increasing when epsilon is increasing, and when epsilon approximately equals to 0.5, power is already approximately equals to 1.


heavy-tailed symmetric alternatives such as t(v)
```{r}
alpha <- 3
n <- 100 
m <- 2500 
epsilon <-seq(0, 1 ,length.out = 30) 
N <- length(epsilon) 
power <- numeric(N) 

#computes the sample skewness coeff. 
sk <- function(x) { 
  xbar <- mean(x) 
  m3 <- mean((x - xbar)^3) 
  m2 <- mean((x - xbar)^2) 
  return( m3 / m2^1.5 ) 
}

#critical value for the skewness test 
cv <- qnorm(0.975, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))

for (j in 1:N) { 
  #for each epsilon 
  e <- epsilon[j] 
  sktests <- numeric(m)
  for (i in 1:m) {
    #for each replicate   
    Y <- sample(0:1, size = n, replace = TRUE, prob = c(1-e, e)) 
    x <- rbeta(n, alpha, alpha) * (Y == 0) + rt(n, 100*alpha) * (Y == 1)
    sktests[i] <- (abs(sk(x)) >= cv)
  }
  power[j] <- mean(sktests) 
} 

#plot power vs epsilon
plot(epsilon, power, type = "b", xlab = bquote(epsilon), ylim = c(0,1)) 
#abline(h = .1, lty = 3)
se <- sqrt(power * (1-power) / m)
#add standard errors
lines(epsilon, power+se, lty = 3)
lines(epsilon, power-se, lty = 3)
```
  
  The empirical power curve is shown in Figure. Note that the power curve crosses the horizontal line corresponding to $\alpha=0.05$ at both endpoints, $\epsilon=0$ and $\epsilon=1$ where the alternative is normally distributed. For $0<\epsilon<1$ the empirical power of the test is greater than 0.05 and highest when $\epsilon$ is about 0.10.

conclusion：After estimating the power of the skewness test of normality against symmetric $Beta(\alpha,\alpha)$ distributions, it comes to a conclusion that the results different for heavy-tailed symmetric alternatives such as $t(v)$. 


## Exercise 6.A
  Use Monte Carlo simulation to investigate whether the empirical Type I error rate of the t-test is approximately equal to the nominal significance level $\alpha$, when the sampled population is non-normal. The t-test is robust to mild departures from normality. Discuss the simulation results for the cases where the sampled population is    
  (i) $\chi ^{2}(1)$      
  (ii) Uniform(0,2)   
  (iii) Exponential(rate=1)
  In each case, test $H_{0} : \mu=\mu_{0}$ vs $H_{0} : \mu\neq\mu_{0}$, where $\mu_{0}$ is the mean of $\chi^{2}(1)$, Uniform(0,2), and Exponential(1), respectively. 

### answer
Case(i): chisq(1)
```{r}
n <- 20 
alpha <- .05
mu0 <- 1 #null hypothesis
m <- 10000 #number of replicates 
p <- numeric(m) #storage for p-values 
for (j in 1:m) { 
  x <- rchisq(n, mu0) 
  ttest <- t.test(x, mu = mu0) 
  p[j] <- ttest$p.value 
  }
p.hat <- mean(p < alpha) 
p.hat
```

  By the Monte Carlo simulation, the empirical Type I error rate of the t-test for the cases where the sampled population is $\chi^{2}(1)$, is much bigger than the nominal significance level $\alpha$.  
  

Case(ii): Uniform(0,2) 
```{r}
n <- 20 
alpha <- 0.05 
mu0 <- 1 #null hypothesis
m <- 10000 #number of replicates 
p <- numeric(m) #storage for p-values 
for (j in 1:m) { 
  x <- runif(n, min = 0, max = 2) 
  ttest <- t.test(x, mu = mu0) 
  p[j] <- ttest$p.value 
  }
p.hat <- mean(p < alpha) 
p.hat
```

  By the Monte Carlo simulation, the empirical Type I error rate of the t-test for the cases where the sampled population is Uniform(0,2), is approximately equal to the nominal significance level $\alpha$.  
  

Case(iii): Exponential(rate=1)
```{r}
n <- 20 
alpha <- .05 
mu0 <- 1  #null hypothesis
m <- 10000 #number of replicates 
p <- numeric(m) #storage for p-values 
for (j in 1:m) { 
  x <- rexp(n, rate = 1) 
  ttest <- t.test(x, mu = mu0) 
  p[j] <- ttest$p.value 
  }
p.hat <- mean(p < alpha) 
p.hat
```

  By the Monte Carlo simulation, the empirical Type I error rate of the t-test for the cases where the sampled population is Exponential(rate=1), is little bigger than the nominal significance level $\alpha$.  
  

## Exercise3: Discussion
  If we obtain the powers for two methods under a particular simulation setting with 10,000 experiments: says, 0.651 for one method and 0.676 for another method. Can we say the powers are different at 0.05 level?
1. What is the corresponding hypothesis test problem?
2. What test should we use? Z-test, two-sample t-test, paired-t-test or McNemar test?
3. What information is needed to test your hypothesis?


### answer
1. Let $P_1$ denote the power for one method, and $P_2$ for another method.Let $T_1$ denote the testing statistic for one method, and $T_2$ for another method.Let $W_1$ denote the rejection area for one method, and $W_2$ for another method.
The significant level is $\alpha=0.05$.Then the test hypotheses are 
$H0 : P1 = P2$  vs  $H1 : P1 \neq P2$.
If H0 is false, we can say the  powers are different at 0.05 level, otherwise, we can't say the powers are different at 0.05 level.


2. Firstly, these four methods will be introduced shortly:  
* Z-test: A Z-test is any statistical test for which the distribution of the test statistic under the null hypothesis can be approximated by a normal distribution. Because of the central limit theorem, many test statistics are approximately normally distributed for large samples. For each significance level, the Z-test has a single critical value (for example, 1.96 for 5% two tailed) which makes it more convenient than the Student's t-test which has separate critical values for each sample size. Therefore, many statistical tests can be conveniently performed as approximate Z-tests if the sample size is large or the population variance is known. If the population variance is unknown (and therefore has to be estimated from the sample itself) and the sample size is not large (n < 30), the Student's t-test may be more appropriate.

* two sample t-test: In statistics, "two sample t-test" is also named "Welch's t-test", or "unequal variances t-test", is a two-sample location test which is used to test the hypothesis that two populations have equal means. It is named for its creator, Bernard Lewis Welch, and is an adaptation of Student's t-test, and is more reliable when the two samples have unequal variances and/or unequal sample sizes. These tests are often referred to as "unpaired" or "independent samples" t-tests, as they are typically applied when the statistical units underlying the two samples being compared are non-overlapping. Given that Welch's t-test has been less popular than Student's t-test and may be less familiar to readers, a more informative name is "Welch's unequal variances t-test" — or "unequal variances t-test" for brevity.

* paired sample t-test: In statistic, paired sample t-test is used to compare two means that are repeated measures for the same participants - scores might be repeated across different measures or across time. It is also used also to compare paired samples, as in a two treatment randomized block design.

* MCNemar test: McNemar's test is a statistical test used on paired nominal data. It is applied to 2 × 2 contingency tables with a dichotomous trait, with matched pairs of subjects, to determine whether the row and column marginal frequencies are equal (that is, whether there is "marginal homogeneity"). It is named after Quinn McNemar, who introduced it in 1947. An application of the test in genetics is the transmission disequilibrium test for detecting linkage disequilibrium. The commonly used parameters to assess a diagnostic test in medical sciences are sensitivity and specificity. Sensitivity is the ability of a test to correctly identify the people with disease. Specificity is the ability of the test to correctly identify those without the disease. Now presume two tests are performed on the same group of patients. And also presume that these tests have identical sensitivity and specificity. In this situation one is carried away by these findings and presume that both the tests are equivalent. However this may not be the case. For this we have to study the patients with disease and patients without disease (by a reference test). We also have to find out where these two tests disagree with each other. This is precisely the basis of McNemar's test. This test compares the sensitivity and specificity of two diagnostic tests on the same group of patients.

After learning four methods, as for this problem, the best chance is "MCNemar test". Because we have two samples and these two samples are not independent.


3. The information what we need is: the rejection area $W_1$, $W_2$, the testing statistic $T_1$, $T_2$.


# 6
## Exercise 7.6
 Efronand Tibshirani discuss the scor (bootstrap) test score data on 88 students who took examinations in five subjects [84, Table 7.1], [188, Table 1.2.1]. The first two tests (mechanics, vectors) were closed book and the last three tests (algebra, analysis, statistics) were open book. Each row of the data frame is a set of scores $(x_{i1},\cdots,x_{i5})$ for the $i^{th}$ student. Use a panel display to display the scatter plots for each pair of test scores. Compare the plot with the sample correlation matrix. Obtain bootstrap estimates of the standard errors for each of the following estimates: $\hat{\rho }_{12}=\hat{\rho}(mec, vec)$, $\hat{\rho }_{34}=\hat{\rho}(alg,ana)$, $\hat{\rho }_{35}=\hat{\rho}(alg, sta)$, $\hat{\rho }_{45}=\hat{\rho}(ana, sta)$.


### answer
```{r}
library(bootstrap)
#par(mfrow = c(2, 2))
plot(scor$mec, scor$vec)
plot(scor$alg, scor$ana)
plot(scor$alg, scor$sta)
plot(scor$ana, scor$sta)

#get the sample correlation matrix
cor(scor)
```

```{r results='asis'}
#Obtain bootstrap estimates of the standard errors
#set up the bootstrap 
B <- 200 #number of replicates
n <- nrow(scor) #sample size
R12 <- R34 <- R35 <- R45 <- numeric(B) #storage for replicates

#bootstrap estimate of standard error of R 
for (b in 1:B) { 
  #randomly select the indices 
  i <- sample(1:n, size = n, replace = TRUE) 
  mec <- scor$mec[i] #i is a vector of indices 
  vec <- scor$vec[i]
  alg <- scor$alg[i]
  ana <- scor$ana[i]
  sta <- scor$sta[i]
  R12[b] <- cor(mec, vec)
  R34[b] <- cor(alg, ana)
  R35[b] <- cor(alg, sta)
  R45[b] <- cor(ana, sta)
}
# to compute standard error by using the bootstrap estimate.
se.R12 <- sd(R12)
se.R34 <- sd(R34)
se.R35 <- sd(R35)
se.R45 <- sd(R45)
# draw a table to present the result.
p <- matrix(c(se.R12, se.R34, se.R35, se.R45), 1)
colnames(p) <- c("Rho_12","Rho_34","Rho_35","Rho_45")
rownames(p) <- "Standard Errors"
knitr::kable(p)
```



## Project 7.B
  Repeat Project 7.A for the sample skewness statistic. Compare the coverage rates for normal populations (skewness 0) and $\chi^2(5)$ distributions (positive skewness).

### answer
Project 7.A
  Conduct a Monte Carlo study to estimate the coverage probabilities of the standard normal bootstrap confidence interval, the basic bootstrap confidence interval, and the percentile confidence interval. Sample from a normal population and check the empirical coverage rates for the sample mean. Find the proportion of times that the confidence intervals miss on the left, and the porportion of times that the confidence intervals miss on the right. 


```{r}
library(boot)
n <- 10
m <- 1e3
B <- 2000
ci.norm <- ci.basic <- ci.perc <- ci.bca <- matrix(0, m, 2) 

#computes the sample skewness coeff.
sk <- function(x,i) { 
  x<-x[i]
  xbar <- mean(x) 
  m3 <- mean((x - xbar)^3) 
  m2 <- mean((x - xbar)^2) 
  return( m3 / m2^1.5 ) 
}
```

the normal populations (skewness 0) distributions
```{r}
sk.norm = 0
for(i in 1:m){ 
  U <- rnorm(n)
  de <- boot(data = U, statistic = sk, B) 
  ci <- boot.ci(de, type = c("norm", "basic", "perc")) 
  ci.norm[i,] <- ci$norm[2:3]
  ci.basic[i,] <- ci$basic[4:5] 
  ci.perc[i,] <- ci$percent[4:5]
  } 
cat('norm =', mean(ci.norm[,1] <= sk.norm & ci.norm[,2] >= sk.norm), 'basic =', mean(ci.basic[,1] <= sk.norm & ci.basic[,2] >= sk.norm), 'perc =', mean(ci.perc[,1] <= sk.norm & ci.perc[,2] >= sk.norm))
```
  
  The coverage rates for normal populations of the standard normal bootstrap confidence interval is `r mean(ci.norm[,1] <= sk.norm & ci.norm[,2] >= sk.norm)`;    
  The coverage rates for normal populations of the basic bootstrap confidence interval is `r mean(ci.basic[,1] <= sk.norm & ci.basic[,2] >= sk.norm)`;   
  The coverage rates for normal populations of the percentile confidence interval is `r mean(ci.perc[,1] <= sk.norm & ci.perc[,2] >= sk.norm)`.


the chisq distributions (positive skewness)
```{r}
sk.chisq = 4/sqrt(10)
for(i in 1:m){ 
  U <- rchisq(n, df = 5)
  de <- boot(data = U, statistic = sk, B) 
  ci <- boot.ci(de, type = c("norm", "basic", "perc")) 
  ci.norm[i,] <- ci$norm[2:3]
  ci.basic[i,] <- ci$basic[4:5] 
  ci.perc[i,] <- ci$percent[4:5]
  } 
cat('norm =', mean(ci.norm[,1] <= sk.chisq & ci.norm[,2] >= sk.chisq), 'basic =', mean(ci.basic[,1] <= sk.chisq & ci.basic[,2] >= sk.chisq), 'perc =', mean(ci.perc[,1] <= sk.chisq & ci.perc[,2] >= sk.chisq))
```

  The coverage rates for $\chi^2(5)$ distribution of the standard normal bootstrap confidence interval is `r mean(ci.norm[,1] <= sk.chisq & ci.norm[,2] >= sk.chisq)`;    
  The coverage rates for $\chi^2(5)$ distribution of the basic bootstrap confidence interval is `r mean(ci.basic[,1] <= sk.chisq & ci.basic[,2] >= sk.chisq)`;   
  The coverage rates for $\chi^2(5)$ distribution of the percentile confidence interval is `r mean(ci.perc[,1] <= sk.chisq & ci.perc[,2] >= sk.chisq)`.


# 7
## Exercise 7.8
 Refer to Exercise 7.7. Obtain the jacknife estimates of bias and standard error of $\hat{\theta}$

### answer
Exercise 7.7
  Refer to Exercise 7.6. Efron and Tibshirani discuss the following example [84, Ch. 7]. The five-dimensional scores data have a $5 \times 5$ covariance matrix $\Sigma$, with positive eigenvalues $\lambda_1>\cdots>\lambda_5$. In principal components analysis, $\theta =\frac{\lambda _1}{\sum_{j=1}^{5}\lambda _j}$ measures the proportion of variance explained by the first principal component. Let $\hat{\lambda_1}>\cdots>\hat{\lambda_5}$ be the eigenvalues of $\hat{\Sigma}$, where $\hat{\Sigma}$ is the MLE of $\Sigma$. Compute the sample estimate $\hat{\theta}=\frac{\hat{\lambda _1}}{\sum_{j=1}^{5}\hat{\lambda_j}}$ of $\theta$. Use bootstrap to estimate the bias and standard error of $\hat{\theta}$.
  
```{r}
# To obtain the parameter theta
library(bootstrap)
library(boot) #for boot function
n <- nrow(scor)
theta.hat <- function(x){
  y <- cov(x)
  lambda <- eigen(y)$values
  theta <- lambda[1] / sum(lambda)
}
```


Via bootstrap in Exercise 7.7
```{r}
set.seed(0)
#set up the bootstrap
B <- 2000
n <- nrow(scor)
theta.boot <- numeric(B)

#bootstrap
for(b in 1 : B){
  i <- sample(1:n, size = n, replace = TRUE)
  x <- scor[i,]
  theta.boot[b] <- theta.hat(x)
}

# Estimate bias and standard error of theta.hat
bias.hat_boot <- mean(theta.boot) - theta.hat(scor)
se.hat_boot <- sd(theta.boot)
# print the result
bias.hat_boot
se.hat_boot
```


Via jackknife in Exercise 7.8
```{r}
theta.jack <- numeric(n)
for(i in 1 : n){
  x <- scor[-i,]
  theta.jack[i] <- theta.hat(x)
}

# Estimate bias and standard error of theta.hat
bias.hat_jack <- (n - 1) * (mean(theta.jack) - theta.hat(scor))
se.hat_jack <- sqrt((n - 1) * mean((theta.jack - mean(theta.jack))^2))
# print the result
bias.hat_jack
se.hat_jack

```

## Exercise 7.10
  In Example 7.18, leave-one-out (n-fold) cross validation was used to select the best fitting model. Repeat the analysis replacing the Log-Log model with a cubic polynomial model. Which of the four models is selected by the cross validation procedure? Which model is selected according to maximum adjusted $R^2$? 


### answer

To display four plots
```{r}
library(DAAG)
magnetic <- ironslag$magnetic
chemical <- ironslag$chemical
a <- seq(10, 40, .1) #sequence for plotting fits
#par(mfrow = c(2,2))

L1 <- lm(magnetic ~ chemical) 
plot(chemical, magnetic, main = "Linear", pch = 16) 
yhat1 <- L1$coef[1] + L1$coef[2] * a 
lines(a, yhat1, lwd=2)

L2 <- lm(magnetic ~ chemical + I(chemical^2)) 
plot(chemical, magnetic, main = "Quadratic", pch = 16) 
yhat2 <- L2$coef[1] + L2$coef[2] * a + L2$coef[3] * a^2 
lines(a, yhat2, lwd=2)

L3 <- lm(log(magnetic) ~ chemical) 
plot(chemical, magnetic, main = "Exponential", pch = 16) 
logyhat3 <- L3$coef[1] + L3$coef[2] * a 
yhat3 <- exp(logyhat3) 
lines(a, yhat3, lwd=2)

L4 <- lm(magnetic ~ chemical + I(chemical^2) + I(chemical^3)) 
plot(chemical, magnetic, main = "cubic", pch = 16) 
yhat4 <- L4$coef[1] + L4$coef[2] * a + L4$coef[3] * a^2 + L4$coef[4] * a^3
lines(a, yhat4, lwd=2)
```


Model selected by the cross validation procedure
```{r}
n <- length(magnetic) #in DAAG ironslag 
e1 <- e2 <- e3 <- e4 <- numeric(n)
# for n-fold cross validation 
# fit models on leave-one-out samples 
for (k in 1:n) { 
  y <- magnetic[-k] 
  x <- chemical[-k]
  
  J1 <- lm(y ~ x) 
  yhat1 <- J1$coef[1] + J1$coef[2] * chemical[k] 
  e1[k] <- magnetic[k] - yhat1
  
  J2 <- lm(y ~ x + I(x^2)) 
  yhat2 <- J2$coef[1] + J2$coef[2] * chemical[k] + J2$coef[3] * chemical[k]^2 
  e2[k] <- magnetic[k] - yhat2
  
  J3 <- lm(log(y) ~ x) 
  logyhat3 <- J3$coef[1] + J3$coef[2] * chemical[k] 
  yhat3 <- exp(logyhat3) 
  e3[k] <- magnetic[k] - yhat3
  
  J4 <- lm(y ~ x + I(x^2) + I(x^3)) 
  yhat4 <- J4$coef[1] + J4$coef[2] * chemical[k] + J4$coef[3] * chemical[k]^2 + J4$coef[4] * chemical[k]^3
  e4[k] <- magnetic[k] - yhat4
} 
c(mean(e1^2), mean(e2^2), mean(e3^2), mean(e4^2)) 
```

According to the prediction error criterion, Model 2, the quadratic model, would be the best fit for the data. 

```{r}
L2
```

The fitted regression equation for Model 2 is 
$\hat{Y}$ = `r L2$coef[1]` + `r L2$coef[2]`X + `r L2$coef[3]`$X^2$


Model selected by maximum adjust $R^2$ 
```{r}
n <- length(magnetic) #in DAAG ironslag 
y <- magnetic
x <- chemical

J1 <- lm(y ~ x) 
summary(J1)$adj.r.squared# to get the adjust R^2

J2 <- lm(y ~ x + I(x^2)) 
summary(J2)$adj.r.squared

J3 <- lm(log(y) ~ x) 
summary(J3)$adj.r.squared

J4 <- lm(y ~ x + I(x^2) + I(x^3)) 
summary(J4)$adj.r.squared
```

According to the prediction error criterion, Model 2, the quadratic model, would be the best fit for the data. 

```{r}
L2
```

The fitted regression equation for Model 2 is 
$\hat{Y}$ = `r L2$coef[1]` + `r L2$coef[2]`X + `r L2$coef[3]`$X^2$


# 8 
## Exercise 8.3
  The Count 5 test for equal variances in Section 6.4 is based on the maximum number of extreme points. Example 6.15 shows that the Count 5 criterion is not applicable for unequal sample sizes. Implement a permutation test for equal variance based on the maximum number of extreme points that applies when sample sizes are not necessarily equal. 

### answer

```{r}
# define the function of "count five test"
count5test <- function(x, y) {
  X <- x - mean(x)
  Y <- y - mean(y)
  outx <- sum(X > max(Y)) + sum(X < min(Y))
  outy <- sum(Y > max(X)) + sum(Y < min(X))
  # get the statistic of "count five test"
  return(as.integer(max(c(outx, outy))))
}
```

```{r}
# get two samples with the same variance while sample sizes are not equal
set.seed(12345)
n1 <- 20
n2 <- 30
mu1 <- mu2 <- 0
sigma1 <- sigma2 <- 1
x <- rnorm(n1, mu1, sigma1)
y <- rnorm(n2, mu2, sigma2)
#centered by sample mean
x <- x - mean(x) 
y <- y - mean(y)
```

```{r}
t0 <- count5test(x,y)
R <- 999 #number of replicates
z <- c(x, y) #pooled sample
K <- 1:(n1+n2)
reps <- numeric(R) #storage for replicates
for (i in 1:R) {
#generate indices k for the first sample
k <- sample(K, size = n1, replace = FALSE)
x1 <- z[k]
y1 <- z[-k] #complement of x1
reps[i] <- count5test(x1, y1)
}
# print the p-value
mean(reps > t0)
```


## Dicussion 
* Power comparison (distance correlation test versus ball covariance test)
       
    Model 1: $Y=X/4+e$    
    Model 2: $Y=X/4\times e$   
    $X\sim N(0_2,I_2)$, $e\sim N(0_2,I_2)$, $X$ and $e$ are independent.    

### answer
```{r}
library(MASS)
library(Ball)
library(boot)

dCov <- function(x, y) {
  x <- as.matrix(x)
  y <- as.matrix(y)
  n <- nrow(x)
  m <- nrow(y)
  if (n != m || n < 2) stop("Sample sizes must agree")
  if (! (all(is.finite(c(x, y)))))
    stop("Data contains missing or infinite values")
  Akl <- function(x) {
    d <- as.matrix(dist(x))
    m <- rowMeans(d)
    M <- mean(d)
    a <- sweep(d, 1, m)
    b <- sweep(a, 2, m)
    return(b + M)
  }
  A <- Akl(x)
  B <- Akl(y)
  dCov <- sqrt(mean(A * B))
}

ndCov2 <- function(z, ix, dims) {
  #dims contains dimensions of x and y
  p <- dims[1]
  q1 <- dims[2] + 1
  d <- p + dims[2]
  x <- z[ , 1:p] #leave x as is
  y <- z[ix, -(1:p)] #permute rows of y
  return(nrow(z) * dCov(x, y)^2)
}

dc.test <- function(z, dims){
  boot.obj <- boot(data = z, statistic = ndCov2, R = R, sim = "permutation",  dims = c(2,2))
  ts <- c(boot.obj$t0,boot.obj$t)
  p.value <- mean(ts >= ts[1])
  list(statistic=ts[1], p.value=p.value)
}
```

```{r}
set.seed(12345)
m <- 100
u <- c(0,0)
sigma <- matrix(c(1,0,0,1), 2, 2)
R <- 1e2
alpha <- 0.1
n <- seq(10,100,10)
power.dc <- power.ball <- numeric(length(n))
p.dc <- p.ball <- numeric(m)
```

Model 1: Y = X/4 + e
```{r}
for(j in 1:length(n)){
 for(i in 1:m){
    x<-matrix(rnorm(n[j]*2),nrow = n[j])
    e<-matrix(rnorm(n[j]*2),nrow = n[j])
    y <- x/4+e
    z <- as.data.frame(cbind(x,y))
    p.dc[i] <- dc.test(z, c(2,2))$p.value
    p.ball[i] <- bcov.test(x, y, R=R, seed = i*12345)$p.value
  }
  power.dc[j] <- mean(p.dc < alpha)
  power.ball[j] <- mean(p.ball < alpha)
}

# plot the power
plot(n, power.dc, type = "o", xlab = "n", ylab = "power", main = "Model 1", col = 1)
lines(n, power.ball, type = "o", col = 2)
legend('bottomright', legend = c('dc', 'ball'), col = 1:2, lty = 1)
```

Model 2: Y = X/4 * e
```{r}
for(j in 1:length(n)){
  for(i in 1:m){
    x<-matrix(rnorm(n[j]*2),nrow = n[j])
    e<-matrix(rnorm(n[j]*2),nrow = n[j])
    y <- x/4*e
    z <- as.data.frame(cbind(x,y))
    p.dc[i] <- dc.test(z, c(2,2))$p.value
    p.ball[i] <- bcov.test(x, y, R=R, seed = i*12345)$p.value
  }
  power.dc[j] <- mean(p.dc < alpha)
  power.ball[j] <- mean(p.ball < alpha)
}

# plot the power
plot(n, power.dc, type = "o", xlab = "n", ylab = "power", main = "Model 1", col = 1)
lines(n, power.ball, type = "o", col = 2)
legend('bottomright', legend = c('dc', 'ball'), col = 1:2, lty = 1)
```

As for model 1, "distance correlation test" would be better
As for model 2, "ball covariance test" would be better.


# 9
## Exercise 9.4
  Implement a random walk Metropolis sampler for generating the standard Laplace distribution (see Exercise 3.2). For the increment, simulate from a normal distribution. Compare the chains generated when different variances are used for the proposal distribution. Also, compute the acceptance rates of each chain.

### answer
  The standard Laplace distribution has density $f(x) = \frac{1}{2}e^{-\left | x \right |}, x \in R$
  
```{r}
laplace <- function(x, mu = 0, lambda = 1){
  return(1/(2*lambda)*exp(-abs(x-mu)/lambda))
}

rw.Metropolis <- function(sigma, x0, N) {
  x <- numeric(N)
  x[1] <- x0
  u <- runif(N)
  k <- 0
  for (i in 2:N) {
    y <- rnorm(1, x[i-1], sigma)
    if (u[i] <= (laplace(y, 0, 1) / laplace(x[i-1], 0, 1)))
      x[i] <- y 
    else {
        x[i] <- x[i-1]
        k <- k + 1
      }
  }
  return(list(x=x, k=k))
}

#par(mfrow = c(2,2))
N <- 2000
sigma <- c(.05, .5, 2, 16)
x0 <- 25
rw1 <- rw.Metropolis(sigma[1], x0, N)
rw2 <- rw.Metropolis(sigma[2], x0, N)
rw3 <- rw.Metropolis(sigma[3], x0, N)
rw4 <- rw.Metropolis(sigma[4], x0, N)
#number of candidate points rejected
accept <- 1-c(rw1$k, rw2$k, rw3$k, rw4$k)/N
print(accept)

plot(rw1$x, type="l", main = paste("accept rate = ",accept[1]), xlab = paste("sigma = ",sigma[1]), ylab = "x")
abline(h = c(log(0.05/2), -log(0.05/2)), col = "red")

plot(rw2$x, type="l", main = paste("accept rate = ",accept[2]), xlab = paste("sigma = ",sigma[2]), ylab = "x")
abline(h = c(log(0.05/2), -log(0.05/2)), col = "red")

plot(rw3$x, type="l", main = paste("accept rate = ",accept[3]), xlab = paste("sigma = ",sigma[3]), ylab = "x")
abline(h = c(log(0.05/2), -log(0.05/2)), col = "red")

plot(rw4$x, type="l", main = paste("accept rate = ",accept[4]), xlab = paste("sigma = ",sigma[4]), ylab = "x")
abline(h = c(log(0.05/2), -log(0.05/2)), col = "red")
```

  In the first plot of Figure with $\sigma = 0.05$, the ratios $r(X_t,Y)$ tend to be large and almost every candidate point is accepted. The increments are small and the chain is almost like a true random walk. Chain 1 has not converged to the target in 2000 iterations. The chain in the second plot generated with $\sigma = 0.5$ is converging little slowly, and very few points are rejected. In the third plot $\sigma = 2$ the chain is mixing well and converging to the target distribution after a short burn-in period of about 50. Finally, in the fourth plot, where $\sigma = 16$, the ratios $r(X_t,Y)$ are smaller and most of the candidate points are rejected. The fourth chain converges, but it is inefficient.
  

# 10  
## Exercises 11.1
  The natural logarithm and exponential functions are inverses of each other, so that mathematically log(exp x) = exp(log x) = x. Show by example that this property does not hold exactly in computer arithmetic. Does the identity hold with near equality? (See all.equal.)

### answer
```{r}
x <- 1000
log(exp(x)) == exp(log(x))
isTRUE(all.equal(log(exp(x)), exp(log(x))))
```


## Exercises 11.5
Write a function to solve the equation
$\frac{2\Gamma (\frac{k}{2})}{\sqrt{\pi(k-1)}\Gamma(\frac{k-1}{2})}\int_{0}^{c_{k-1}}(1+\frac{u^2}{k-1})^{-k/2}du$ 
=
$\frac{2\Gamma (\frac{k+1}{2})}{\sqrt{\pi k}\Gamma (\frac{k}{2})}\int_{0}^{c_k}(1+\frac{u^2}{k})^{-(k+1)/2}du$
for a, where
$c_k = \sqrt{\frac{a^2 k}{k+1-a^2}}$
compare the solutions with the points A(k) in Exercise 11.4


### answer
Exercise 11.4
Find the intersection points A(k) in (0, $\sqrt{k}$) of the curves
$S_{k-1}(a) = P(t(k-1) > \sqrt{\frac{a^2(k-1)}{k-a^2}})$
and
$S_{k}(a) = P(t(k) > \sqrt{\frac{a^2(k)}{k+1-a^2}})$
for k = 4 : 25, 100, 500, 1000, where t(k) is a Student t random variable with k degrees of freedom. (These intersection points determine the critical values for a t-test for scale-mixture errors proposed by Szekely [260].)

The solution of exercise 11.4 as followed:
```{r}
k <- c(4:25, 100, 500, 1000)
r1 <- rep(0,length(k))
for(i in 1:length(k)){
  ki <- k[i]
  ck <- function(a, ki){
    sqrt(a^2*ki/(ki+1-a^2))
  }

  s <- function(a, ki){
    pt(ck(a, ki), df=ki) - pt(ck(a, ki-1), df=ki-1)
  }
  
  f <- function(a){
    return(s(a,ki))
  }
  r1[i] <- uniroot(f, lower = 1e-6, upper = sqrt(ki)-1e-6)$root
}
r1
```

solution for exercise 11.5
```{r}
k <- c(4:25)
r2 <- rep(0,length(k))
for(i in 1:length(k)){
  ki <- k[i]
  
  h <- function(a, ki){
    ck <- function(a, ki){
       sqrt(a^2*ki/(ki+1-a^2))
    } 
    
    g <- function(u){
      (1+u^2/ki)^(-(ki+1)/2)
    }
    
    # for simplily, get the log of the function
    r<-lgamma((ki+1)/2)-log(sqrt(pi*ki))-lgamma(ki/2)+log(integrate(g, lower = 0, upper=ck(a,ki), rel.tol=.Machine$double.eps^0.25)$value)
    return(r)
  }
  
  f <- function(a){
    h(a, ki) - h(a, ki-1)
  }
  r2[i] <- uniroot(f, lower = 1e-7, upper = sqrt(ki)-0.15)$root
}
r2
```

```{r}
ki <- 100
r3 <- uniroot(f, lower = 1e-7, upper = sqrt(ki)-3)$root
r3
```

```{r}
ki <- 500
r4 <- uniroot(f, lower = 1e-7, upper = sqrt(ki)-20)$root
r4
```

```{r}
ki <- 1000
r5 <- uniroot(f, lower = 1e-7, upper = sqrt(ki)-26)$root
r5
```
Compare with the result in 11.4, can find that the solution are near equal when k is small such as from 4 to 20, but when k is lager enough, the result is not good.


## A-B-O blood type problem
 * Let the three alleles be A, B, and O with allele frequencies p, q, and r. The 6 genotype frequencies under HWE and complete counts are as follows.

    ```{r,echo=FALSE}
        dat <- rbind(Genotype=c('AA','BB','OO','AO','BO','AB','Sum'),
                     Frequency=c('p^2','q^2','r^2','2pr','2qr','2pq',1),
                     Count=c('nAA','nBB','nOO','nAO','nBO','nAB','n'))
        knitr::kable(dat,format='latex')
    ```
    + Observed data: $n_{A\cdot}=n_{AA}+n_{AO}=28$ (A-type), $n_{B\cdot}=n_{BB}+n_{BO}=24$ (B-type), $n_{OO}=41$ (O-type), $n_{AB}=70$ (AB-type).
    
    + Use EM algorithm to solve MLE of $p$ and $q$ (consider missing data $n_{AA}$ and $n_{BB}$).
    
    + Record the log-maximum likelihood values in M-steps, are they increasing?
 

### answer

denote $x = (n_A, n_B, n_{AB}, n_O)$, $y = (n_{AA}, n_{AO}, n_{BB}, n_{BO}, n_{OO})
the likelihood function of y is $log f(y|P)$ 
= $n_{AA}log(p^2) + n_{AO}log(2pr) + n_{BB}log(q^2) + n_{BO}log(2qr) + n_{AB}log(pq) + n_{OO}log(r^2) + log\frac{n!}{n_{AA}! n_{AO}! n_{BB}! n_{BO}! n_{AB}! n_{OO}!}$


```{r}
# define the function to compute n!
pro <- function(n){
  if(n<0) 
    print("warning: your input is wrong!")
  else if(n==0) 
    print(1)
  else {
    s <- length(n)
    s[1] <- 1
    for(i in 2:n){
      s[i] <- i*s[i-1]
    }
    return(s[n])
  }
}
```



```{r}
# Use EM algorithm to solve MLE of p and q 
blood <- function(P, n.obs){
  n <- sum(n.obs)
  na <- n.obs[1]
  nb <- n.obs[2]
  nab <- n.obs[3]
  no <- n.obs[4]
  noo <- no
  
  ## E step
#  cat(P, "\n")  # P is the vector of original probability c(p,q,r)
  p <- q <- r <- rep(0, m)
  lnf <- rep(0, m-1)
  p[1] <- P[1]
  q[1] <- P[2]
  r[1] <- 1 - P[1] - P[2]
  for(i in 2:m){
    # instead old value by new value
    p.old <- p[i-1]  
    q.old <- q[i-1]
    r.old <- r[i-1]
    
    ## M step
    den1 <- p.old^2 + 2 * p.old * r.old
    naa <- na * p.old^2 / den1
    nao <- 2 * na * p.old * r.old / den1
    den2 <- q.old^2 + 2 * q.old * r.old
    nbb <- nb * q.old^2 / den2
    nbo <- 2 * nb * q.old * r.old / den2
    p[i] <- (2*naa + nao + nab)/(2*n)
    q[i] <- (2*nbb + nbo + nab)/(2*n)
    r[i] <- (2*noo + nao + nbo)/(2*n)
    lnf[i-1] <- naa*log(p[i]^2)+nao*log(2*p[i]*r[i])+nbb*log(q[i]^2)+nbo*log(2*q[i]*r[i])+nab*log(p[i]*q[i])+noo*log(r[i]^2)+log(pro(n)/(pro(naa)*pro(nao)*pro(nbb)*pro(nbo)*pro(nab)*pro(noo)))
  }
  
  return(list(P = c(p[m], q[m], r[m]), lh = lnf[1:50]))  # return the first 50 values
}
n.obs <- c(28, 24, 70, 41)
m <- 1000 #repicate times
P <- c(1/3, 1/3)  # set the original value

c <- blood(P, n.obs)
c$P
#c$lh
plot(c$lh, xlab="n", ylab="likelihood", type="b", cex=.5, col=2)
```

Convergence times are 20, and from the table, we can know that p is converged to 0.32734, q is converged to 0.31043.

# 11
## Exercise 3 (P204)
Use both for loops and lapply() to fit linear models to the mtcars using the formulas stored in this list:     
formulas <- list(    
  mpg ~ disp,     
  mpg ~ I(1 / disp),    
  mpg ~ disp + wt,    
  mpg ~ I(1 / disp) + wt    
) 

### answer
```{r}
formulas <- list(    
  mpg ~ disp,     
  mpg ~ I(1 / disp),    
  mpg ~ disp + wt,    
  mpg ~ I(1 / disp) + wt    
) 

# use for loops
r1 <- list()
for (i in 1:4){
  r1[[i]]  <- lm(formula = formulas[[i]], data = mtcars)
}
r1

# use lapply()
r2 <- lapply(formulas, function(formulas){
  lm(formula = formulas, data = mtcars)
})
r2
```

Results by using for loops and lapply are same.


## Exercise 4 (P204)
Fit the model mpg ~ disp to each of the bootstrap replicates of mtcars in the list below by using a for loop and lapply(). Can you do it without an anonymous function?          

### answer
```{r}
bootstraps <- lapply(1:10, function(i) {    
  rows <- sample(1: nrow(mtcars), rep = TRUE)     
  mtcars[rows, ]     
}) 

# use for loops
r3 <- list()
for (i in 1:10){
r3[[i]] <- lm(formula = mpg ~ disp, data = bootstraps[[i]])
}
r3

# use lapply
r4 <- lapply(bootstraps, function(x) lm(formula = mpg ~ disp, data = x))
r4
```

Results by using two methods are same.


## Exercise 5 (P204)
For each model in the previous two exercises, extract R2 using the function below.    
rsq <- function(mod) summary(mod)$r.squared   

### answer
```{r}
rsq <- function(mod) summary(mod)$r.squared 
R1 <- lapply(r1, rsq)
R1
R2 <- lapply(r2, rsq)
R2
R3 <- lapply(r3, rsq)
R3
R4 <- lapply(r4, rsq)
R4
```

## Exercise 3 (P214)
The following code simulates the performance of a t-test for non-normal data. Use sapply() and an anonymous function to extract the p-value from every trial.    
trials <- replicate(100, t.test(rpois(10, 10), rpois(7, 10)), simplify = FALSE)        
Extra challenge: get rid of the anonymous function by using [[ directly.   

### answer
```{r}
trials <- replicate(100, t.test(rpois(10, 10), rpois(7, 10)), simplify = FALSE) 
# use sapply
p1 <- sapply(trials, function(x) x$p.value)
p1

# use for loops
p2 <- numeric(100)
for (i in 1:100){
p2[i] <- trials[[i]]$p.value
}
```


## Exercise 7 (P214)
Implement mcsapply(), a multicore version of sapply(). Can you implement mcvapply(), a parallel version of vapply()? Why or why not?

### answer
```{r}
library(parallel)
f <- function(x) c(sum(x), mean(x), sd(x))
x <- list(1:10, c(2,3,4), c(TRUE,FALSE,TRUE,TRUE))

# use mcsapply
mcsapply <- function(x, f){
  cl <- makeCluster(4)
  result <- parLapply(cl, x, f)
  stopCluster(cl) 
  return(unlist(result))
}
# print the system.time
system.time(mcsapply(x, f))  

# use mcvapply
mcvapply <- function(x, f){
  cl <- makeCluster(4)
  result <- vapply(x,f,c("a" = 0, "b" = 0, "c" = 0))
  stopCluster(cl) 
  return(result)
}
# print the system.time
system.time(mcvapply(x, f))
```

# 12
## Exercise 
You have already written an R function for Exercise 9.4 (page 277, Statistical Computing with R). Rewrite an Rcpp function for the same task.
 * Compare the generated random numbers by the two functions using qqplot.
 * Campare the computation time of the two functions with microbenchmark.
 * Comments your results.

### answer
  The standard Laplace distribution has density $f(x) = \frac{1}{2}e^{-\left | x \right |}, x \in R$
  
```{r}
# R function

laplace <- function(x, mu = 0, lambda = 1){
  return(1/(2*lambda)*exp(-abs(x-mu)/lambda))
}

rw <- function(sigma, x0, N) {
  x <- numeric(N)
  x[1] <- x0
  u <- runif(N)
  k <- 0
  for (i in 2:N) {
    y <- rnorm(1, x[i-1], sigma)
    if (u[i] <= (laplace(y, 0, 1) / laplace(x[i-1], 0, 1)))
      x[i] <- y 
    else {
        x[i] <- x[i-1]
        k <- k + 1
      }
  }
  return(x)
}


# Cpp function
library(Rcpp)
library(microbenchmark)
cppFunction('NumericVector rwC(double sigma, double x_0,int N) {
  NumericVector x(N);
  NumericVector U=runif(N,0,1);
  x(0)=x_0; 
  double y;double a;double b;
  for (int i=1; i<N; i++){
    y = rnorm(1,x(i-1),sigma)[0];
    a = 0.5 * exp(-abs(y));
    b = 0.5 * exp(-abs(x(i-1)));
    if (U[i] <= a/b){
      x(i) = y;
    }
    else{
      x(i)=x(i-1);
    }
  }
  return x;
}
')

# define variables
N <- 10000
sigma <- c(0.5, 2, 8, 16)
x0 <- 5
#par(mfrow = c(2,2))
for (i in 1:4){
  # qqplot:
  r <- rw(sigma[i],x0,N)
  R <- as.vector(r)
  C <- rwC(sigma[i],x0,N)
  qqplot(R,C, main = paste("sigma = ",sigma[i]))
  points(x=seq(-8,6), y=seq(-8,6), type = "l", col = "red")
}

for (i in 1:4){
  # compare two function:
  ts <- microbenchmark(R=rw(sigma[i],x0,N), Cpp=rwC(sigma[i],x0,N))
  print(summary(ts)[,c(1,3,5,6)])
}

```

From the above, we can find that the result of R and Cpp function are almost same, but the computition cost of R is more expensive, so if it is possible, we'd better to choose Cpp function to solve the question.